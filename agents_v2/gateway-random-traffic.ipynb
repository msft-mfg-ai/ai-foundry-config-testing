{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate random model traffic with v2 Agents in Foundry\n",
    "This notebook creates and runs an agent from AI Foundry\n",
    "\n",
    "Best way to set it up is with [uv](https://docs.astral.sh/uv/)\n",
    "\n",
    "1. in `agents` directory run `uv sync` (if python is missing, install it using `uv python install`)\n",
    "2. in VSCode press [Ctrl+Shift+P] and select `Python: Select Interpreter`, choose the one from `agents` directory: `./agents/.venv/bin/python3.xx`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1\n",
    "Get projects from foundry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from azure.identity.aio import DefaultAzureCredential\n",
    "from azure.ai.projects.aio import AIProjectClient\n",
    "\n",
    "sys.path.insert(1, \"./src\")  # add code directory to path for imports\n",
    "\n",
    "from foundry_utils import get_ai_foundry_projects\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "deployments = [\"gpt-4.1-mini\", \"gpt-5-mini\", \"o3-mini\"]\n",
    "subscription_id = os.environ.get(\"AZURE_AI_FOUNDRY_SUBSCRIPTION_ID\")\n",
    "resource_group = os.environ.get(\"AZURE_AI_FOUNDRY_RESOURCE_GROUP\")\n",
    "account_name = os.environ.get(\"AZURE_AI_FOUNDRY_NAME\")\n",
    "\n",
    "# Get all project endpoints\n",
    "project_endpoints = await get_ai_foundry_projects(\n",
    "    subscription_id=subscription_id,\n",
    "    resource_group=resource_group,\n",
    "    account_name=account_name,\n",
    ")\n",
    "\n",
    "# Create AIProjectClient and agents_utils for each project\n",
    "project_clients = []\n",
    "creds = DefaultAzureCredential()\n",
    "\n",
    "for endpoint in project_endpoints:\n",
    "    if endpoint:\n",
    "        project_client = AIProjectClient(endpoint=endpoint, credential=creds)\n",
    "        await project_client.__aenter__()\n",
    "        project_clients.append(project_client)\n",
    "        print(f\"Created client for endpoint: {endpoint}\")\n",
    "\n",
    "print(f\"\\nTotal clients created: {len(project_clients)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send random requests to random models for each project\n",
    "import sys\n",
    "\n",
    "sys.path.insert(1, \"./src\")  # add code directory to path for imports\n",
    "from foundry_utils import get_gateway_connections\n",
    "from agents_utils import agents_utils\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "import time\n",
    "from openai import APIStatusError, APIError\n",
    "from azure.core.exceptions import HttpResponseError\n",
    "\n",
    "\n",
    "# Seed random with current time to ensure different values each run\n",
    "random.seed(time.time())\n",
    "\n",
    "# Configuration\n",
    "min_requests_per_project = 3\n",
    "max_requests_per_project = 10\n",
    "prompts = [\n",
    "    \"What is 2 + 2?\",\n",
    "    \"Tell me a joke\",\n",
    "    \"What's the capital of France?\",\n",
    "    \"Explain quantum computing in one sentence\",\n",
    "    \"What is the meaning of life?\",\n",
    "    \"Write a haiku about coding\",\n",
    "    \"What color is the sky?\",\n",
    "    \"Name three programming languages\",\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for idx, (project_client) in enumerate(project_clients):\n",
    "    endpoint = project_endpoints[idx]\n",
    "    num_requests = random.randint(min_requests_per_project, max_requests_per_project)\n",
    "    gateway_connections = await get_gateway_connections(project_client)\n",
    "    print(f\"Gateway connections: {gateway_connections}\")\n",
    "    agents_client = agents_utils(project_client)\n",
    "    connection_name = (\n",
    "        gateway_connections[\"ai_gateway_connection_dynamic\"]\n",
    "        or gateway_connections[\"ai_gateway_connection_static\"]\n",
    "    )\n",
    "    print(f\"Using connection: {connection_name}\")\n",
    "    if not connection_name:\n",
    "        print(f\"No gateway connection found for project {endpoint}, skipping...\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Project {idx + 1}: {endpoint}\")\n",
    "    print(f\"Sending {num_requests} random requests\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    openai_client = project_client.get_openai_client()\n",
    "\n",
    "    for i in range(num_requests):\n",
    "        # Pick random model and prompt\n",
    "        model = random.choice(deployments)\n",
    "        prompt = random.choice(prompts)\n",
    "        request_id = None\n",
    "        result = None\n",
    "        error_msg = None\n",
    "        output = None\n",
    "\n",
    "        try:\n",
    "            agent = await agents_client.create_agent(\n",
    "                name=\"temp-agent\",\n",
    "                model_gateway_connection=connection_name,\n",
    "                deployment_name=model,\n",
    "                delete_before_create=False,\n",
    "            )\n",
    "\n",
    "            # Create conversation\n",
    "            conversation = await openai_client.conversations.create(\n",
    "                items=[\n",
    "                    {\n",
    "                        \"type\": \"message\",\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": prompt,\n",
    "                    }\n",
    "                ],\n",
    "            )\n",
    "\n",
    "            # Get response\n",
    "            response = await openai_client.responses.create(\n",
    "                conversation=conversation.id,\n",
    "                extra_body={\"agent\": {\"name\": agent.name, \"type\": \"agent_reference\"}},\n",
    "                input=\"\",\n",
    "            )\n",
    "\n",
    "            request_id = response._request_id\n",
    "            result = \"SUCCESS\"\n",
    "            output = response.output_text[:100] if response.output_text else \"No output\"\n",
    "\n",
    "            print(\n",
    "                f\"  [{i+1}/{num_requests}] Model: {model} | SUCCESS | {output[:50]}...\"\n",
    "            )\n",
    "\n",
    "        except (APIStatusError, APIError, HttpResponseError) as e:\n",
    "            request_id = (\n",
    "                e.response.headers.get(\"x-request-id\", \"N/A\")\n",
    "                if hasattr(e, \"response\") and e.response\n",
    "                else \"N/A\"\n",
    "            )\n",
    "            result = \"ERROR\"\n",
    "            error_msg = str(e)\n",
    "            output = error_msg\n",
    "            print(f\"  [{i+1}/{num_requests}] Model: {model} | ERROR | {error_msg}...\")\n",
    "\n",
    "        except Exception as e:\n",
    "            result = \"ERROR\"\n",
    "            error_msg = str(e)\n",
    "            output = error_msg\n",
    "            print(f\"  [{i+1}/{num_requests}] Model: {model} | ERROR | {error_msg}...\")\n",
    "\n",
    "        results.append(\n",
    "            {\n",
    "                \"Project\": endpoint.split(\"/\")[-1] if endpoint else f\"Project_{idx}\",\n",
    "                \"Model\": model,\n",
    "                \"Request #\": i + 1,\n",
    "                \"Request ID\": request_id or \"N/A\",\n",
    "                \"Prompt\": prompt[:30] + \"...\" if len(prompt) > 30 else prompt,\n",
    "                \"Result\": result,\n",
    "                \"Output\": output[:50] if output else \"N/A\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "# Create DataFrame and display results\n",
    "df = pd.DataFrame(results)\n",
    "print(\"\\n\\n\" + \"=\" * 80)\n",
    "print(\"=== RESULTS TABLE ===\")\n",
    "print(\"=\" * 80)\n",
    "print(df.to_string(index=False))\n",
    "\n",
    "# Save results to CSV\n",
    "df.to_csv(\"gateway_random_traffic_results.csv\", index=False)\n",
    "print(\"\\nResults saved to gateway_random_traffic_results.csv\")\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\n\\n=== SUMMARY BY PROJECT AND MODEL ===\")\n",
    "summary = df.groupby([\"Project\", \"Model\", \"Result\"]).size().unstack(fill_value=0)\n",
    "print(summary)\n",
    "\n",
    "print(\"\\n\\n=== SUMMARY BY RESULT ===\")\n",
    "print(df[\"Result\"].value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents_v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

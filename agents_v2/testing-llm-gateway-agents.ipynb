{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Agents v2 in AI Foundry\n",
    "This notebook creates and runs an agent from AI Foundry\n",
    "\n",
    "Best way to set it up is with [uv](https://docs.astral.sh/uv/)\n",
    "\n",
    "1. in `agents` directory run `uv sync` (if python is missing, install it using `uv python install`)\n",
    "2. in VSCode press [Ctrl+Shift+P] and select `Python: Select Interpreter`, choose the one from `agents` directory: `./agents/.venv/bin/python3.xx`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1\n",
    "Create Project client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import atexit\n",
    "import jsonref\n",
    "import os\n",
    "from azure.identity.aio import DefaultAzureCredential, AzureDeveloperCliCredential\n",
    "from azure.ai.projects.aio import AIProjectClient\n",
    "from azure.ai.projects.models import (\n",
    "    PromptAgentDefinition,\n",
    "    MCPTool,\n",
    "    Tool,\n",
    "    OpenApiAgentTool,\n",
    "    OpenApiFunctionDefinition,\n",
    "    OpenApiAnonymousAuthDetails,\n",
    ")\n",
    "from openai.types.responses.response_input_param import (\n",
    "    McpApprovalResponse,\n",
    "    ResponseInputParam,\n",
    ")\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# import logging\n",
    "\n",
    "# # Clear any existing handlers\n",
    "# for handler in logging.root.handlers[:]:\n",
    "#     logging.root.removeHandler(handler)\n",
    "\n",
    "# # Set up logging with a format that shows request IDs\n",
    "# log_format = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    "# logging.basicConfig(level=logging.WARNING, format=log_format, force=True)\n",
    "\n",
    "# # Create a handler for our loggers\n",
    "# console_handler = logging.StreamHandler()\n",
    "# console_handler.setLevel(logging.DEBUG)\n",
    "# console_handler.setFormatter(logging.Formatter(log_format))\n",
    "\n",
    "# # Azure SDK HTTP logging - this captures request/response headers including x-request-id\n",
    "# azure_http_logger = logging.getLogger('azure.core.pipeline.policies.http_logging_policy')\n",
    "# azure_http_logger.addHandler(console_handler)\n",
    "# azure_http_logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# # OpenAI HTTP logging\n",
    "# openai_logger = logging.getLogger('openai')\n",
    "# openai_logger.addHandler(console_handler)\n",
    "# openai_logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# # httpx logging (used by openai client)\n",
    "# httpx_logger = logging.getLogger('httpx')\n",
    "# httpx_logger.addHandler(console_handler)\n",
    "# httpx_logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# # AI Projects logging\n",
    "# ai_logger = logging.getLogger('azure.ai.projects')\n",
    "# ai_logger.addHandler(console_handler)\n",
    "# ai_logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv(override=True)\n",
    "\n",
    "endpoint = os.environ.get(\"AZURE_AI_FOUNDRY_CONNECTION_STRING\")\n",
    "deployment_name = os.environ.get(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "api_version = os.environ.get(\"AZURE_OPENAI_API_VERSION\", None)\n",
    "tenant_id = os.environ.get(\"AZURE_TENANT_ID\", None)\n",
    "\n",
    "ai_agent_settings = {\n",
    "    \"endpoint\": endpoint,\n",
    "    \"model_deployment_name\": deployment_name,\n",
    "    \"api_version\": api_version,\n",
    "}\n",
    "print(ai_agent_settings)\n",
    "\n",
    "if os.environ.get(\"USE_AZURE_DEV_CLI\") == \"true\":\n",
    "    print(\"Using Azure Developer CLI Credential\")\n",
    "\n",
    "creds = (\n",
    "    AzureDeveloperCliCredential(tenant_id=tenant_id)\n",
    "    if os.environ.get(\"USE_AZURE_DEV_CLI\") == \"true\"\n",
    "    else DefaultAzureCredential()\n",
    ")\n",
    "await creds.__aenter__()\n",
    "\n",
    "# uncomment to test token aquisition\n",
    "# token_test  = creds.get_token(\"https://ai.azure.com\")\n",
    "# print(f\"Token for https://ai.azure.com: {token_test.token[:10]}...\")\n",
    "\n",
    "client = AIProjectClient(endpoint=endpoint, credential=creds)\n",
    "await client.__aenter__()\n",
    "\n",
    "# info = creds.get_token_info(\"https://ai.azure.com/.default\")\n",
    "# print(f\"Token info: {info}\")\n",
    "\n",
    "\n",
    "async def get_agents():\n",
    "    all_agents = []\n",
    "    async for agent in client.agents.list():\n",
    "        all_agents.append(agent)\n",
    "    return all_agents\n",
    "\n",
    "\n",
    "async def create_agent(\n",
    "    name: str,\n",
    "    model_gateway_connection: str = None,\n",
    "    instructions=\"You are a helpful assistant that answers general questions\",\n",
    "    deployment_name: str = os.environ.get(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\"),\n",
    "    delete_before_create: bool = True,\n",
    "    tools: list[Tool] = [],\n",
    "):\n",
    "\n",
    "    model = (\n",
    "        f\"{model_gateway_connection}/{deployment_name}\"\n",
    "        if model_gateway_connection\n",
    "        else deployment_name\n",
    "    )\n",
    "\n",
    "    # check if agent \"MyV2Agent\" exists\n",
    "    all_agents = await get_agents()\n",
    "    agent_names = [agent.name for agent in all_agents]\n",
    "    agent = None\n",
    "\n",
    "    # this is temporary?\n",
    "    if name in agent_names and delete_before_create:\n",
    "        # delete the agent because of a bug?\n",
    "        print(f\"Deleting existing agent {name} before creating a new one\")\n",
    "        await client.agents.delete(agent_name=name)\n",
    "        agent_names.remove(name)\n",
    "\n",
    "    if name not in agent_names:\n",
    "        agent = await client.agents.create(\n",
    "            name=name,\n",
    "            definition=PromptAgentDefinition(\n",
    "                model=model, instructions=instructions, tools=tools\n",
    "            ),\n",
    "        )\n",
    "        print(\n",
    "            f\"Agent created (id: {agent.id}, name: {agent.name}, version: {agent.versions.latest.version} using model {agent.versions.latest.definition.model})\"\n",
    "        )\n",
    "    else:\n",
    "        agent = await client.agents.update(\n",
    "            agent_name=name,\n",
    "            definition=PromptAgentDefinition(\n",
    "                model=model, instructions=instructions, tools=tools\n",
    "            ),\n",
    "        )\n",
    "        print(\n",
    "            f\"Agent updated (id: {agent.id}, name: {agent.name}, version: {agent.versions.latest.version} using model {agent.versions.latest.definition.model})\"\n",
    "        )\n",
    "    return agent\n",
    "\n",
    "\n",
    "# List connections\n",
    "print()\n",
    "print(\"--- Connections ---\")\n",
    "model_gateway_connection_static = None\n",
    "model_gateway_connection_dynamic = None\n",
    "ai_gateway_connection_static = None\n",
    "ai_gateway_connection_dynamic = None\n",
    "\n",
    "async for connection in client.connections.list():\n",
    "    print(\n",
    "        f\"Connection ID: {connection.id}, Name: {connection.name}, Type: {connection.type} Default: {connection.is_default}\"\n",
    "    )\n",
    "    if connection.type == \"ModelGateway\" and \"static\" in connection.name.lower():\n",
    "        model_gateway_connection_static = connection.name\n",
    "        print(\n",
    "            f\"  - Static Model gateway connection found: {model_gateway_connection_static}\"\n",
    "        )\n",
    "    if connection.type == \"ModelGateway\" and \"static\" not in connection.name.lower():\n",
    "        model_gateway_connection_dynamic = connection.name\n",
    "        print(\n",
    "            f\"  - Dynamic Model gateway connection found: {model_gateway_connection_dynamic}\"\n",
    "        )\n",
    "    if connection.type == \"ApiManagement\" and \"static\" in connection.name.lower():\n",
    "        ai_gateway_connection_static = connection.name\n",
    "        print(\n",
    "            f\"  - Static API Management gateway connection found: {ai_gateway_connection_static}\"\n",
    "        )\n",
    "    if connection.type == \"ApiManagement\" and \"static\" not in connection.name.lower():\n",
    "        ai_gateway_connection_dynamic = connection.name\n",
    "        print(\n",
    "            f\"  - Dynamic API Management gateway connection found: {ai_gateway_connection_dynamic}\"\n",
    "        )\n",
    "\n",
    "# List agents\n",
    "print()\n",
    "print(\"--- Agents ---\")\n",
    "agents = await get_agents()\n",
    "for agent in agents:\n",
    "    print(\n",
    "        f\"Agent ID: {agent.id}, Name: {agent.name}, version: {agent.versions.latest.version} Properties: {agent.as_dict()}\"\n",
    "    )\n",
    "\n",
    "\n",
    "async def cleanup():\n",
    "    \"\"\"Close all async clients properly\"\"\"\n",
    "    try:\n",
    "        await client.close()  # If .close() method exists\n",
    "    except:\n",
    "        await client.__aexit__(None, None, None)\n",
    "    try:\n",
    "        await creds.close()\n",
    "    except:\n",
    "        await creds.__aexit__(None, None, None)\n",
    "    print(\"Clients closed\")\n",
    "\n",
    "\n",
    "# Register cleanup for kernel shutdown (optional)\n",
    "\n",
    "\n",
    "def sync_cleanup():\n",
    "    try:\n",
    "        loop = asyncio.get_event_loop()\n",
    "        if loop.is_running():\n",
    "            loop.create_task(cleanup())\n",
    "        else:\n",
    "            loop.run_until_complete(cleanup())\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "atexit.register(sync_cleanup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run 10 requests for each gateway connection and capture request IDs\n",
    "import pandas as pd\n",
    "from openai import APIStatusError, APIError\n",
    "from azure.core.exceptions import HttpResponseError\n",
    "\n",
    "# Collect all gateway connections to test\n",
    "gateway_connections = {\n",
    "    \"model_gateway_static\": model_gateway_connection_static,\n",
    "    \"model_gateway_dynamic\": model_gateway_connection_dynamic,\n",
    "    \"ai_gateway_static\": ai_gateway_connection_static,\n",
    "    \"ai_gateway_dynamic\": ai_gateway_connection_dynamic,\n",
    "}\n",
    "\n",
    "# Filter out None connections\n",
    "active_connections = {k: v for k, v in gateway_connections.items() if v is not None}\n",
    "print(f\"Testing {len(active_connections)} gateway connections: {list(active_connections.keys())}\")\n",
    "\n",
    "results = []\n",
    "num_requests = 5\n",
    "delete_agent_before_create = False\n",
    "\n",
    "for conn_name, conn_value in active_connections.items():\n",
    "    print(f\"\\n--- Testing {conn_name} ({conn_value}) ---\")\n",
    "    \n",
    "    for i in range(num_requests):\n",
    "        request_id = None\n",
    "        result = None\n",
    "        error_msg = None\n",
    "        \n",
    "        try:\n",
    "            agent_name = f\"TestAgent_{conn_name}\".replace(\" \", \"-\").replace(\"_\", \"-\")[:63]\n",
    "\n",
    "            # Create agent for this connection\n",
    "            agent = await create_agent(\n",
    "                name=agent_name,\n",
    "                model_gateway_connection=conn_value,\n",
    "                delete_before_create=delete_agent_before_create,\n",
    "            )\n",
    "            \n",
    "            openai_client = client.get_openai_client()\n",
    "            \n",
    "            # Create conversation\n",
    "            conversation = await openai_client.conversations.create(\n",
    "                items=[\n",
    "                    {\n",
    "                        \"type\": \"message\",\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": f\"What is 2 + {i}? Reply with just the number.\",\n",
    "                    }\n",
    "                ],\n",
    "            )\n",
    "            \n",
    "            # Get response\n",
    "            response = await openai_client.responses.create(\n",
    "                conversation=conversation.id,\n",
    "                extra_body={\"agent\": {\"name\": agent.name, \"type\": \"agent_reference\"}},\n",
    "                input=\"\",\n",
    "            )\n",
    "            \n",
    "            # Extract request ID from response\n",
    "            request_id = response._request_id\n",
    "            result = \"SUCCESS\"\n",
    "            output = response.output_text[:50] if response.output_text else \"No output\"\n",
    "            \n",
    "            results.append({\n",
    "                \"Connection\": conn_name,\n",
    "                \"Request #\": i + 1,\n",
    "                \"Request ID\": request_id,\n",
    "                \"Result\": result,\n",
    "                \"Output\": output,\n",
    "            })\n",
    "            print(f\"  Request {i+1}: SUCCESS - {request_id}. Response: {output}...\")\n",
    "            \n",
    "        except (APIStatusError, APIError, HttpResponseError) as e:\n",
    "            # Extract request ID from error response headers\n",
    "            request_id = e.response.headers.get('x-request-id', 'N/A') if hasattr(e, 'response') else 'N/A'\n",
    "            result = \"ERROR\"\n",
    "            error_msg = str(e)\n",
    "            \n",
    "            results.append({\n",
    "                \"Connection\": conn_name,\n",
    "                \"Request #\": i + 1,\n",
    "                \"Request ID\": request_id,\n",
    "                \"Result\": result,\n",
    "                \"Output\": error_msg,\n",
    "            })\n",
    "            print(f\"  Request {i+1}: ERROR - {request_id} - {error_msg}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            result = \"ERROR\"\n",
    "            error_msg = str(e)\n",
    "            \n",
    "            results.append({\n",
    "                \"Connection\": conn_name,\n",
    "                \"Request #\": i + 1,\n",
    "                \"Request ID\": \"N/A\",\n",
    "                \"Result\": result,\n",
    "                \"Output\": error_msg,\n",
    "            })\n",
    "            print(f\"  Request {i+1}: ERROR - {error_msg}\")\n",
    "\n",
    "# Create DataFrame and display results\n",
    "df = pd.DataFrame(results)\n",
    "print(\"\\n\\n=== RESULTS TABLE ===\")\n",
    "print(df.to_string(index=False))\n",
    "\n",
    "# save results to CSV\n",
    "df.to_csv(\"gateway_connection_test_results.csv\", index=False)\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\n\\n=== SUMMARY ===\")\n",
    "summary = df.groupby(['Connection', 'Result']).size().unstack(fill_value=0)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run agent using static gateway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = await create_agent(\n",
    "    name=\"MyV2Agent\", model_gateway_connection=ai_gateway_connection_dynamic, delete_before_create=True\n",
    ")\n",
    "openai_client = client.get_openai_client()\n",
    "conversation = await openai_client.conversations.create(\n",
    "    items=[\n",
    "        {\n",
    "            \"type\": \"message\",\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What is the size of Poland in square miles?\",\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "print(\n",
    "    f\"Created conversation with agent {agent.name} with initial user message (id: {conversation.id})\"\n",
    ")\n",
    "\n",
    "response = await openai_client.responses.create(\n",
    "    conversation=conversation.id,\n",
    "    extra_body={\"agent\": {\"name\": agent.name, \"type\": \"agent_reference\"}},\n",
    "    input=\"\",\n",
    ")\n",
    "print(f\"Response id: {response.id}\")\n",
    "print(f\"Response output: {response.output_text}\")\n",
    "print(f\"Response cost: {response.to_dict()[\"usage\"]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run agent using dynamic gateway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = await create_agent(\n",
    "    name=\"MyV2Agent\", model_gateway_connection=model_gateway_connection_dynamic, delete_before_create=True\n",
    ")\n",
    "openai_client = client.get_openai_client()\n",
    "conversation = await openai_client.conversations.create(\n",
    "    items=[\n",
    "        {\"type\": \"message\", \"role\": \"user\", \"content\": \"What is the history of Warsaw?\"}\n",
    "    ],\n",
    ")\n",
    "print(\n",
    "    f\"Created conversation with agent {agent.name} with initial user message (id: {conversation.id})\"\n",
    ")\n",
    "\n",
    "response = await openai_client.responses.create(\n",
    "    conversation=conversation.id,\n",
    "    extra_body={\"agent\": {\"name\": agent.name, \"type\": \"agent_reference\"}},\n",
    "    input=\"\",\n",
    ")\n",
    "print(f\"Response output: {response.output_text}\")\n",
    "print(f\"Response cost: {response.to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = await create_agent(\n",
    "    name=\"MyAgentGpt5Mini\",\n",
    "    model_gateway_connection=model_gateway_connection_dynamic,\n",
    "    deployment_name=\"azure-gpt-5-mini\",\n",
    "    delete_before_create=True,\n",
    ")\n",
    "openai_client = client.get_openai_client()\n",
    "conversation = await openai_client.conversations.create(\n",
    "    items=[\n",
    "        {\n",
    "            \"type\": \"message\",\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Tell me hi in 10 random languages.\",\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "print(\n",
    "    f\"Created conversation with agent {agent.name} for streaming (id: {conversation.id})\"\n",
    ")\n",
    "\n",
    "# Create streaming response\n",
    "response_stream_events = await openai_client.responses.create(\n",
    "    conversation=conversation.id,\n",
    "    extra_body={\"agent\": {\"name\": agent.name, \"type\": \"agent_reference\"}},\n",
    "    input=\"\",\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "print(\"Streaming response:\")\n",
    "events_received = []\n",
    "\n",
    "async for event in response_stream_events:\n",
    "    previous_event = events_received[-1] if len(events_received) > 0 else None\n",
    "    if previous_event and previous_event[\"type\"] == event.type:\n",
    "        previous_event[\"count\"] += 1\n",
    "    else:\n",
    "        events_received.append({\"type\": event.type, \"count\": 1})\n",
    "\n",
    "    if event.type == \"response.created\":\n",
    "        print(f\"Stream response created with ID: {event.response.id}\\n\")\n",
    "    elif event.type == \"response.output_text.delta\":\n",
    "        print(event.delta, end=\"\", flush=True)\n",
    "    elif event.type == \"response.text.done\":\n",
    "        print(f\"\\n\\nResponse text done. Access final text in 'event.text'\")\n",
    "    elif event.type == \"response.completed\":\n",
    "        print(\n",
    "            f\"\\n\\nResponse completed. Access final text in 'event.response.output_text'\"\n",
    "        )\n",
    "        print(f\"Response cost: {event.response.to_dict()['usage']}\")\n",
    "        print(f\"Full response text: {event.response.output_text}\")\n",
    "\n",
    "for index, event in enumerate(events_received):\n",
    "    print(f\"{index} event: {event}\")\n",
    "\n",
    "# print(f\"\\n\\nFull response length: {len(full_response)} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper for streaming\n",
    "from openai import AsyncStream\n",
    "from openai.types.responses import ResponseStreamEvent\n",
    "\n",
    "\n",
    "async def process_stream(stream: AsyncStream[ResponseStreamEvent]):\n",
    "    events_received = []\n",
    "    input_list = []\n",
    "    response_id = None\n",
    "    full_response = \"\"\n",
    "\n",
    "    async for event in stream:\n",
    "        previous_event = events_received[-1] if len(events_received) > 0 else None\n",
    "        if previous_event and previous_event[\"type\"] == event.type:\n",
    "            previous_event[\"count\"] += 1\n",
    "        else:\n",
    "            events_received.append({\"type\": event.type, \"count\": 1})\n",
    "\n",
    "        if event.type == \"response.created\":\n",
    "            print(f\"Stream response created with ID: {event.response.id}\\n\")\n",
    "        elif event.type == \"response.output_text.delta\":\n",
    "            print(event.delta, end=\"\", flush=True)\n",
    "        elif event.type == \"response.text.done\":\n",
    "            print(\"\\n\\nResponse text done. Access final text in 'event.text'\")\n",
    "        elif event.type == \"response.output_item.added\":\n",
    "            print(f\"\\n\\nResponse output item added: {event.item}\")\n",
    "            if event.item.type == \"mcp_approval_request\":\n",
    "                input_list.append(\n",
    "                    McpApprovalResponse(\n",
    "                        type=\"mcp_approval_response\",\n",
    "                        approve=True,\n",
    "                        approval_request_id=event.item.id,\n",
    "                    )\n",
    "                )\n",
    "        elif event.type == \"response.output_item.done\":\n",
    "            print(f\"\\n\\nResponse output item done: {event.item}\")\n",
    "        elif event.type == \"response.completed\":\n",
    "            response_id = event.response.id\n",
    "            print(\n",
    "                \"\\n\\nResponse completed. Access final text in 'event.response.output_text'\"\n",
    "            )\n",
    "            print(f\"Response cost: {event.response.to_dict()['usage']}\")\n",
    "            full_response = event.response.output_text\n",
    "    return events_received, input_list, response_id, full_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcp_tool = MCPTool(\n",
    "    server_label=\"api-specs\",\n",
    "    server_url=\"https://gitmcp.io/Azure/azure-rest-api-specs\",\n",
    "    require_approval=\"always\",\n",
    ")\n",
    "\n",
    "# Create tools list with proper typing for the agent definition\n",
    "tools: list[Tool] = [mcp_tool]\n",
    "\n",
    "agent = await create_agent(\n",
    "    name=\"MyAgentGpt5MiniTools\",\n",
    "    model_gateway_connection=model_gateway_connection_dynamic,\n",
    "    deployment_name=\"azure-gpt-5-mini\",\n",
    "    delete_before_create=True,\n",
    "    instructions=\"You are a helpful agent that can use MCP tools to assist users. Use the available MCP tools to answer questions and perform tasks.\",\n",
    "    tools=tools,\n",
    ")\n",
    "openai_client = client.get_openai_client()\n",
    "conversation = await openai_client.conversations.create(\n",
    "    items=[\n",
    "        {\n",
    "            \"type\": \"message\",\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Please summarize the Azure REST API specifications Readme\",\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "print(\n",
    "    f\"Created conversation with agent {agent.name} for streaming (id: {conversation.id})\"\n",
    ")\n",
    "\n",
    "# Create streaming response\n",
    "events_received = []\n",
    "input_list = []\n",
    "response_id = None\n",
    "input = \"\"\n",
    "request_count = 0\n",
    "\n",
    "while True:\n",
    "    response_stream_events = await openai_client.responses.create(\n",
    "        conversation=conversation.id if response_id is None else \"\",\n",
    "        previous_response_id=response_id,\n",
    "        extra_body={\"agent\": {\"name\": agent.name, \"type\": \"agent_reference\"}},\n",
    "        input=input,\n",
    "        stream=True,\n",
    "        # tool_choice='required'\n",
    "    )\n",
    "\n",
    "    print(f\"Streaming response {request_count}:\")\n",
    "    events_received, input_list, response_id, full_response = await process_stream(\n",
    "        response_stream_events\n",
    "    )\n",
    "\n",
    "    for index, event in enumerate(events_received):\n",
    "        print(f\"{request_count}.{index} event: {event}\")\n",
    "\n",
    "    if len(input_list) == 0:\n",
    "        break\n",
    "    input = input_list\n",
    "    print(\n",
    "        f\"\\n\\n{request_count} Submitting approval for {len(input_list)} tools, including {input_list[0]['approval_request_id']}\"\n",
    "    )\n",
    "    request_count += 1\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non Streaming MCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcp_tool = MCPTool(\n",
    "    server_label=\"docs\",\n",
    "    # private MCP server\n",
    "    # server_url=\"https://aca-mcp-qmjrpcr7svlm2.whitesea-e3999951.norwayeast.azurecontainerapps.io/\",\n",
    "    # public MCP server\n",
    "    server_url=\"https://gitmcp.io/Azure/azure-rest-api-specs\",\n",
    "    require_approval=\"always\",\n",
    ")\n",
    "\n",
    "with open(\"weather.json\", \"r\") as f:\n",
    "    openapi_weather = jsonref.loads(f.read())\n",
    "    # private openAPI server\n",
    "    # openapi_weather[\"servers\"] = [{\"url\": 'https://aca-openapi-qmjrpcr7svlm2.whitesea-e3999951.norwayeast.azurecontainerapps.io'}]\n",
    "    # public openAPI server\n",
    "    openapi_weather[\"servers\"] = [{\"url\": \"https://wttr.in\"}]\n",
    "\n",
    "open_api_tool = OpenApiAgentTool(\n",
    "    openapi=OpenApiFunctionDefinition(\n",
    "        name=\"get_weather\",\n",
    "        spec=openapi_weather,\n",
    "        description=\"Retrieve weather information for a location.\",\n",
    "        auth=OpenApiAnonymousAuthDetails(),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create tools list with proper typing for the agent definition\n",
    "tools: list[Tool] = [mcp_tool]\n",
    "\n",
    "agent = await create_agent(\n",
    "    name=\"MyAgentGpt5MiniTools\",\n",
    "    model_gateway_connection=model_gateway_connection_static,\n",
    "    deployment_name=\"azure-gpt-5-mini\",\n",
    "    # deployment_name=\"gpt-4.1\",\n",
    "    delete_before_create=True,\n",
    "    instructions=\"You are a helpful agent that can use MCP tools to assist users. Use the available MCP tools to answer questions and perform tasks.\",\n",
    "    tools=tools,\n",
    ")\n",
    "openai_client = client.get_openai_client()\n",
    "conversation = await openai_client.conversations.create(\n",
    "    items=[\n",
    "        {\"type\": \"message\", \"role\": \"user\", \"content\": \"Summarize the readme for me\"}\n",
    "    ],\n",
    ")\n",
    "print(\n",
    "    f\"Created conversation with agent {agent.name} for streaming (id: {conversation.id})\"\n",
    ")\n",
    "\n",
    "response = await openai_client.responses.create(\n",
    "    conversation=conversation.id,\n",
    "    extra_body={\"agent\": {\"name\": agent.name, \"type\": \"agent_reference\"}},\n",
    "    input=\"\",\n",
    ")\n",
    "\n",
    "# Process any MCP approval requests that were generated\n",
    "input_list: ResponseInputParam = []\n",
    "for item in response.output:\n",
    "    if item.type == \"mcp_approval_request\":\n",
    "        if item.id:\n",
    "            # Automatically approve the MCP request to allow the agent to proceed\n",
    "            # In production, you might want to implement more sophisticated approval logic\n",
    "            input_list.append(\n",
    "                McpApprovalResponse(\n",
    "                    type=\"mcp_approval_response\",\n",
    "                    approve=True,\n",
    "                    approval_request_id=item.id,\n",
    "                )\n",
    "            )\n",
    "\n",
    "if len(input_list) > 0:\n",
    "    print(\"Final input:\")\n",
    "    print(input_list)\n",
    "\n",
    "    agent = await create_agent(\n",
    "        name=\"MyAgentGpt5MiniTools\",\n",
    "        # model_gateway_connection=model_gateway_connection_static,\n",
    "        # deployment_name=\"azure-gpt-5-mini\",\n",
    "        deployment_name=\"gpt-4.1\",\n",
    "        delete_before_create=True,\n",
    "        instructions=\"You are a helpful agent that can use MCP tools to assist users. Use the available MCP tools to answer questions and perform tasks.\",\n",
    "        tools=tools,\n",
    "    )\n",
    "\n",
    "    # Send the approval response back to continue the agent's work\n",
    "    # This allows the MCP tool to access the GitHub repository and complete the original request\n",
    "    response = await openai_client.responses.create(\n",
    "        input=input_list,\n",
    "        previous_response_id=response.id,\n",
    "        extra_body={\"agent\": {\"name\": agent.name, \"type\": \"agent_reference\"}},\n",
    "    )\n",
    "\n",
    "# Print result (should contain \"Azure\")\n",
    "print(f\"==> Result: {response.output_text}\")\n",
    "print(response.to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No agents MCP\n",
    "Run without referencing the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcp_tool = MCPTool(\n",
    "    server_label=\"docs\",\n",
    "    # private MCP server\n",
    "    # server_url=\"https://aca-mcp-qmjrpcr7svlm2.whitesea-e3999951.norwayeast.azurecontainerapps.io/\",\n",
    "    # public MCP server\n",
    "    server_url=\"https://gitmcp.io/Azure/azure-rest-api-specs\",\n",
    "    require_approval=\"always\",\n",
    ")\n",
    "\n",
    "with open(\"weather.json\", \"r\") as f:\n",
    "    openapi_weather = jsonref.loads(f.read())\n",
    "    # private openAPI server\n",
    "    # openapi_weather[\"servers\"] = [{\"url\": 'https://aca-openapi-qmjrpcr7svlm2.whitesea-e3999951.norwayeast.azurecontainerapps.io'}]\n",
    "    # public openAPI server\n",
    "    openapi_weather[\"servers\"] = [{\"url\": \"https://wttr.in\"}]\n",
    "\n",
    "open_api_tool = OpenApiAgentTool(\n",
    "    openapi=OpenApiFunctionDefinition(\n",
    "        name=\"get_weather\",\n",
    "        spec=openapi_weather,\n",
    "        description=\"Retrieve weather information for a location.\",\n",
    "        auth=OpenApiAnonymousAuthDetails(),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create tools list with proper typing for the agent definition\n",
    "tools: list[Tool] = [mcp_tool]\n",
    "\n",
    "\n",
    "openai_client = client.get_openai_client()\n",
    "conversation = await openai_client.conversations.create(\n",
    "    items=[\n",
    "        {\"type\": \"message\", \"role\": \"user\", \"content\": \"Summarize the readme for me\"}\n",
    "    ],\n",
    ")\n",
    "print(f\"Created conversation with model for streaming (id: {conversation.id})\")\n",
    "\n",
    "response = await openai_client.responses.create(\n",
    "    conversation=conversation.id,\n",
    "    # model='gpt-4.1',\n",
    "    model=f\"{model_gateway_connection_static}/{deployment_name}\",\n",
    "    tools=tools,\n",
    "    input=\"\",\n",
    ")\n",
    "\n",
    "# Process any MCP approval requests that were generated\n",
    "input_list: ResponseInputParam = []\n",
    "for item in response.output:\n",
    "    if item.type == \"mcp_approval_request\":\n",
    "        if item.id:\n",
    "            # Automatically approve the MCP request to allow the agent to proceed\n",
    "            # In production, you might want to implement more sophisticated approval logic\n",
    "            input_list.append(\n",
    "                McpApprovalResponse(\n",
    "                    type=\"mcp_approval_response\",\n",
    "                    approve=True,\n",
    "                    approval_request_id=item.id,\n",
    "                )\n",
    "            )\n",
    "\n",
    "if len(input_list) > 0:\n",
    "    print(\"Final input:\")\n",
    "    print(input_list)\n",
    "\n",
    "    # Send the approval response back to continue the agent's work\n",
    "    # This allows the MCP tool to access the GitHub repository and complete the original request\n",
    "    response = await openai_client.responses.create(\n",
    "        input=input_list,\n",
    "        # model='gpt-4.1',\n",
    "        model=f\"{model_gateway_connection_static}/{deployment_name}\",\n",
    "        tools=tools,\n",
    "        previous_response_id=response.id,\n",
    "    )\n",
    "\n",
    "# Print result (should contain \"Azure\")\n",
    "print(f\"==> Result: {response.output_text}\")\n",
    "print(response.to_dict())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents_v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
